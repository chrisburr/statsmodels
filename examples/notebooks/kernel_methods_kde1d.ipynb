{
 "metadata": {
  "name": "",
  "signature": "sha256:1546be2e3c02d2bc23e1d31b575aefdc3202eb952817003c6a8de1e52d579143"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "1D Kernel Density Estimation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "%matplotlib inline\n",
      "import numpy as np\n",
      "from scipy import stats\n",
      "import statsmodels.api as sm\n",
      "import matplotlib.pyplot as plt\n",
      "from statsmodels.distributions.mixture_rvs import mixture_rvs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "A simple example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To start with, we'll look at estimating the density of a mixture of gaussian kernels, just to see the simplest use case."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(12345)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "obs_dist1 = mixture_rvs([.25,.75], size=10000, dist=[stats.norm, stats.norm],\n",
      "                kwargs = (dict(loc=-1,scale=.5),dict(loc=1,scale=.5)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kde = sm.kernel_methods.KDE(obs_dist1)\n",
      "mod = kde.fit()\n",
      "support, density = mod.grid()\n",
      "mod.bandwidth"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(12, 8))\n",
      "ax = fig.add_subplot(111)\n",
      "ax.hist(obs_dist1, bins=50, normed=True, color='red', alpha=.5)\n",
      "ax.plot(support, density, lw=2, color='black');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Bounded domain"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a second example, we will look at a mixture between a normal and beta distribution, such that the domain is bounded on one side."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "obs_dist2 = mixture_rvs([.25,.75], size=10000, dist=[stats.norm, stats.beta],\n",
      "            kwargs = (dict(loc=-1,scale=.5),dict(loc=1,scale=1,args=(1,.5))))\n",
      "def pdf_dist2(x):\n",
      "    return stats.norm(loc=-1, scale=.5).pdf(x) / 3 + 2*stats.beta(1, .5, loc=1, scale=1).pdf(x)/3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, let's see what happens if we don't mention the upper bound on the beta distribution:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kde = sm.kernel_methods.KDE(obs_dist2)\n",
      "mod = kde.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs, ys = mod.grid()\n",
      "xs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that, naturally, the expected support of the distribution extend beyond the support of the beta distribution (in our case, it stops at 2). And we can see in the following plot that the peak is badly estimated:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(12, 8))\n",
      "ax = fig.add_subplot(111)\n",
      "ax.hist(obs_dist2, bins=50, normed=True, color='red', alpha=.5)\n",
      "ax.plot(xs, ys, lw=2, color='black')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also see that stopping the domain at 2 on the evaluation, we \"loose\" some mass in the density (nearly 10% of it):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gr = sm.kernel_methods.Grid.fromBounds([-4, 2], shape=1024)\n",
      "ys = mod(gr)\n",
      "print(\"Sum of the density:\", gr.integrate(ys))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, if we fix the upper bound ... we don't loose any more mass"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kde.upper = 2\n",
      "mod2 = kde.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs2, ys2 = mod2.grid()\n",
      "print(\"Total density:\", xs2.integrate(ys2))\n",
      "xs2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(12, 8))\n",
      "ax = fig.add_subplot(111)\n",
      "ax.hist(obs_dist2, bins=50, normed=True, color='red', alpha=.5)\n",
      "ax.plot(xs2, ys2, lw=2, color='black')\n",
      "ylims = ax.get_ylim()\n",
      "ax.plot(xs2, pdf_dist2(xs2), color='blue', linestyle='--')\n",
      "ax.set_ylim(*ylims)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, we can see that the peak, although better estimated, is still largely under-estimated by this method!\n",
      "\n",
      "This is because the default method has been chosen to be fast and reasonable is many cases, but not if the distribution diverges on the boundary. For this case, a better method is the first order approximation called 'linear combination':"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kde.method = sm.kernel_methods.kde_methods.LinearCombination\n",
      "mod3 = kde.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs3, ys3 = mod3.grid()\n",
      "print(\"Total density: \", xs3.integrate(ys3))  # Using the integrate method of the Grid object"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can note that, due to the first order approximation, the total density is not quite 1. In this particular case, it is over-estimated by about 5%. But when we plt the graph, we can see that the peak is much better approximated now:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(12, 8))\n",
      "ax = fig.add_subplot(111)\n",
      "ax.hist(obs_dist2, bins=50, normed=True, color='red', alpha=.5)\n",
      "ax.plot(xs3, ys3, lw=2, color='black', label='Linear Combination estimate')\n",
      "ylims = ax.get_ylim()\n",
      "ax.plot(xs3, pdf_dist2(xs3), color='blue', linestyle='--', label='Real PDF')\n",
      "ax.set_ylim(*ylims)\n",
      "plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Other functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition to the PDF, 1D methods also provide:\n",
      "\n",
      "* Cumulative Density Function\n",
      "* Survival function\n",
      "* Hazard function\n",
      "* ..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs, ys = mod2.cdf_grid()\n",
      "f = plt.figure(figsize=(12, 8))\n",
      "ax = f.add_subplot(111)\n",
      "ax.plot(xs, ys)\n",
      "ax.set_title('CDF')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs, ys = mod2.sf_grid()\n",
      "f = plt.figure(figsize=(12, 8))\n",
      "ax = f.add_subplot(111)\n",
      "ax.plot(xs, ys)\n",
      "ax.set_title('Survival function')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs, ys = mod2.icdf_grid()\n",
      "f = plt.figure(figsize=(12, 8))\n",
      "ax = f.add_subplot(111)\n",
      "ax.plot(xs, ys)\n",
      "ax.set_title('Inverse CDF')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}